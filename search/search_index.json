{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Introduction","text":""},{"location":"#overview","title":"Overview","text":"<p>Welcome to the documentation for the HULKs software. The section titles can be found in the bar at the top, inside a section the chapters will be listed on the left. Longer chapters will provide a table of contents on the right.</p> <p>TODO: the following paragraph needs to be reformulated</p> <p>We plan to release a \"final\" code release each year after RoboCup for which the documentation should be complete and correct. In addition to the yearly code release, we publish a weekly snapshot on a separate branch. Due to the frequent changes in the weekly branch, the documentation can be outdated at times.</p> <p>All our code is released under the terms of the GNU General Public License v3.</p> <p>If you have questions that are not answered here, please file issues in our GitHub issue tracker so we can fix the documentation for everyone. As our team has limited resources, we don't expect to be able to give much in-depth support individually.</p>"},{"location":"#documentation-status","title":"Documentation Status","text":"Section Status Setup Incomplete Framework Incomplete, partially outdated Tooling Incomplete Operating System Missing Robotics Missing Workflow Missing"},{"location":"framework/communication/","title":"Communication","text":"<p>TODO: Elaborate</p> <ul> <li>Communication<ul> <li>Overview &amp; Diagram<ul> <li>Asynchronous Tasks</li> <li>Channels</li> </ul> </li> <li>Database Subscriptions<ul> <li>Notifications</li> <li>Subscription Management &amp; Clients</li> <li>Extract subscribed types/images from databases and send them to clients</li> </ul> </li> <li>Parameters<ul> <li>Propagate changed parameters to cyclers</li> <li>Subscription Management &amp; Clients</li> </ul> </li> <li>(WebSocket) Protocol/(JSON) (De-)Serialization<ul> <li>Acceptor</li> <li>Connection Setup (WebSocket handshake)</li> <li>Sender/Receiver</li> <li>Message Format</li> </ul> </li> </ul> </li> </ul>"},{"location":"framework/cyclers/","title":"Cyclers","text":"<p>A cycler in the HULKs robotic control software is a subcomponent that cycles nodes. The name \"cycler\" comes from the characteristic that it contains a loop that iterates over incoming data and produces output data in each iteration. The cyclers call their internal <code>cycle()</code> function in each iteration. This <code>cycle()</code> function consists of three steps:</p> <ol> <li>Prepare: Wait for new data and prepare cycle</li> <li>Process: Run nodes on the received data</li> <li>Finalize: E.g. send actuator commands or store data before starting the next cycle</li> </ol> <p>Multiple cyclers exist in the whole robotic control software. One of the main tasks of the framework is to allow cyclers to communicate with each other. For example, in the prepare step, data from other cyclers and communication is gathered. In addition, during the finalize step, data produced in the process step of this cycle may need to be communicated back to other cyclers.</p> <p>Cyclers are separated into the control cycler and multiple perception cyclers e.g. the vision cycler.</p>"},{"location":"framework/cyclers/#control-cycler","title":"Control Cycler","text":"<p>The control cycler is the central cycler that runs in realtime synchronized to the LoLA interval (83 Hz). It receives sensor data from HULA/LoLA via the Hardware Interface and produces actuator output which is sent back to HULA/LoLA. The control cycler integrates data from all other perception cyclers in the filtering pipeline. Features for assisting in data integration in the filtering pipeline are explained in Filtering. The control cycler contains all robotics code that needs to be evaluated in each realtime cycle. In other words, all nodes that are required to generate new outputs are included. Nodes that can be excluded or need to much computation, for example the vision pipeline, are executed in their own perception cyclers.</p>"},{"location":"framework/cyclers/#perception-cyclers","title":"Perception Cyclers","text":"<p>Beside the central control cycler, multiple perception cyclers exist which perceive data from the outside world and preprocess it. The outputs of each cycle are integrated in the control cycler to be respected for its realtime outputs. Since perception cyclers run in parallel to the control cycler and the control cycler is able to integrate historic data, perception cyclers may run at different cycle intervals. Perception cyclers normally wait on an event triggered from outside e.g. a new camera image or network message. The beginning of the processing is announced to the control cycler in the prepare step. In addition, perception cyclers acquire requested data from the control cycler. The perception cycle's output data is sent to the control cycler at the end of the cycle in the finalize step. More information about the interleaving of perceived data can be found in Filtering. The following perception cyclers exist:</p> <ul> <li>audio: Receives audio data from the Hardware Interface e.g. from NAO microphones</li> <li>spl_network: Waits for incoming network messages or outgoing message sending requests from other cyclers.   Each cycle either preprocesses the incoming messages (e.g. by parsing) or sends the outgoing messages to the network.</li> <li>vision_top: Receives top camera images from the Hardware Interface and processes them to extract several features.</li> <li>vision_bottom: Similar to vision_top but receives camera images from the bottom camera.</li> </ul>"},{"location":"framework/databases_and_types/","title":"Databases &amp; Types","text":"<p>TODO: Elaborate</p> <p>TODO: <code>crates/</code>?</p> <p>TODO: Explain (de-)serialization of types (Example code!)</p> <ul> <li>Databases/Types<ul> <li>Databases contain types</li> <li>(MainOutputs and AdditionalOutputs separated)</li> <li>Entries are always Options (-&gt; Error Handling)</li> </ul> </li> </ul>"},{"location":"framework/directory_structure/","title":"Directory Structure","text":"<p>TODO: Add <code>crates</code> directory</p> <p>TODO: Add <code>twix</code></p> <p>TODO: Check if up-to-date</p> <p>The main code repository represents a monorepo containing many parts of the robotic control software and several tools. The directory structure is organized as follows:</p> <ul> <li><code>.github/</code>: GitHub Pull Request template and Actions workflow for the Continuous Integration the HULKs are using for development</li> <li><code>docs/</code>: This documentation</li> <li><code>etc/</code>: All additional files necessary when deploying the code to a robot<ul> <li><code>parameters/</code>: Parameter files that are deployed to NAOs and are read during startup</li> <li><code>motions/</code>: Motion files that can be played back on a robot</li> <li><code>neural_networks/</code>: Neural network files for e.g. the ball detection</li> <li><code>poses/</code> and <code>sounds/</code>: Legacy files (may be removed at some time)</li> </ul> </li> <li><code>macros/</code>: Rust sub-crate providing e.g. the node macros</li> <li><code>node_attributes/</code>: Rust sub-crate providing macro attribute parsing for the node macros</li> <li><code>scripts/</code>: Legacy scripts and files (may be removed at some time)</li> <li><code>sdk/</code>: SDK download directory and version selection symlink</li> <li><code>spl_network_messages/</code>: Rust sub-crate providing SPL message parsing including GameController messages</li> <li><code>src/</code>: Source code of the robotic control software<ul> <li><code>audio/</code>: Audio cycler and all nodes that belong to it</li> <li><code>behavior_simulator/</code>: Special runtime that is able to execute a subset of control nodes for behavior simulation</li> <li><code>bin/</code>: Code for executables that can be built, e.g. <code>nao</code> and <code>webots</code> (these contain <code>main()</code>)</li> <li><code>control/</code>: Control cycler and all nodes that belong to it</li> <li><code>framework/</code>: Code regarding the framework containing e.g. filtering and thread communication primitives or the parameters hierarchy<ul> <li><code>communication/</code>: Communication subcomponent containing the interface to the cyclers and all file system and socket I/O</li> </ul> </li> <li><code>hardware/</code>: Hardware interface definition and several implementations for the build targets e.g. NAO and Webots, see Hardware Interface</li> <li><code>spl_network/</code>: SPL network cycler and all nodes that belong to it</li> <li><code>types/</code>: Rust types that are used throughout the robotics code and framework</li> <li><code>vision/</code>: Vision cycler and all nodes that belong to it</li> </ul> </li> <li><code>tests/</code>: Additional data needed for tests of the robotic control software</li> <li><code>tools/</code>: Miscellaneous projects and tools more or less related to the code<ul> <li><code>ci/</code>: Dockerfiles and scripts for the Continuous Integration the HULKs are using for development</li> <li><code>depp/</code>: Small tool to create a list of dependencies for Yocto Rust recipies (alternative to <code>cargo-bitbake</code>)</li> <li><code>fanta/</code>: Debug client that can attach to communication and dump received data to standard output</li> <li><code>flora/</code>: Graphical debug client that can attach to communication and visualize the current state of the robot</li> <li><code>hula/</code>: Executable which runs on the NAO to provide the HULKs-level abstraction, a wrapper around LoLA, see Hardware Interface</li> <li><code>libPython/</code>: Legacy scripts and files (may be removed at some time)</li> <li><code>machine-learning/</code>: Tooling and training data for machine learning e.g. for ball detection</li> <li><code>pepsi/</code>: Mainly a tool for deploying and interacting with the NAO</li> <li><code>sprite/</code>: Behavior simulator frontend which can visualize the recorded behavior simulation</li> <li><code>TextToSpeech/</code>: Legacy files (may be removed at some time)</li> </ul> </li> <li><code>uvcvideo/</code>: Rust sub-crate providing Linux USB Video Class driver support for NAO cameras</li> <li><code>webots/</code>: Root directory of webots simulation directory structure</li> </ul>"},{"location":"framework/error_handling/","title":"Error Handling","text":"<p>TODO: Elaborate</p> <ul> <li>Error Handling<ul> <li>3 ways to handle errors<ul> <li>Set a main output to none: Happens when the node is unable to generate this output (e.g. when inputs are not available or there was a temporary error inside of the node)<ul> <li>Recoverable, expected to be resolved in the next cycle</li> </ul> </li> <li>Return <code>Err(...)</code> from <code>cycle()</code><ul> <li>Unrecoverable, but framework is allowed to shutdown gracefully, expected that it will not improve in the next cycles/in the future</li> </ul> </li> <li>Panic with e.g. <code>panic!()</code> or by <code>unwrap()</code>ing<ul> <li>Unrecoverable, immediate shutdown, kernel will take down the whole process, there is no way to gracefully shutdown</li> </ul> </li> </ul> </li> </ul> </li> </ul>"},{"location":"framework/filtering/","title":"Filtering","text":"<p>TODO: Elaborate</p> <ul> <li>FutureQueue/Filtering<ul> <li>Overview: Time diagram/plot</li> <li>Motivation: Filters need to have monotonic updates<ul> <li>What needs a filter node to do in each cycle?<ul> <li>Roll-back temporary measurements from last cycle</li> <li>Apply persistent measurements</li> <li>Temporarily apply temporary measurements</li> </ul> </li> </ul> </li> <li>FutureQueue (each Perception Cycler has one to communicate to Control)<ul> <li>Producer<ul> <li>announce</li> <li>finalize</li> </ul> </li> <li>Consumer<ul> <li>consume</li> </ul> </li> </ul> </li> <li>PersistentDatabases consumes from multiple FutureQueues and reorganizes data<ul> <li>persistent vs. temporary</li> </ul> </li> <li>PersistentInputs (Interface for the filter nodes)<ul> <li>persistent vs. temporary</li> </ul> </li> </ul> </li> </ul>"},{"location":"framework/hardware_interface/","title":"Hardware Interface","text":"<p>TODO: Elaborate</p> <ul> <li>Hardware Interface<ul> <li>Trait<ul> <li><code>produce_sensor_data()</code></li> </ul> </li> <li>NAO<ul> <li>HardwareId retrieval (from HULA)</li> <li>LoLA/HAL/HULA<ul> <li>Explain abbreviations</li> <li>Overview: State/Connection/Network/Component Diagram, DataFlow Model</li> <li>Socket Location and that it is a Unix Socket</li> <li>Proxy<ul> <li>Message extraction and injection</li> <li>Message format</li> <li>LED animations</li> </ul> </li> <li>Aliveness<ul> <li>Network: Message format, UDP, multicast, JSON</li> <li>Service states</li> </ul> </li> <li><code>produce_sensor_data()</code></li> </ul> </li> <li>Cameras<ul> <li>Video4Linux</li> <li>Buffering, Zero-copy (-&gt; Cycler)</li> <li>Camera setup (registers)</li> </ul> </li> <li>Audio<ul> <li>ALSA</li> <li>ALSA configuration</li> <li>Later: Audio playback, Text-to-speech</li> </ul> </li> </ul> </li> <li>Webots<ul> <li>HardwareId retrieval (robot name)</li> <li>Webots bindings</li> <li><code>produce_sensor_data()</code></li> <li>Image, audio transfer to different threads</li> <li>Simulation World</li> <li>Directory structure, symlink</li> </ul> </li> </ul> </li> </ul>"},{"location":"framework/logging/","title":"Logging","text":"<p>TODO: Elaborate</p>"},{"location":"framework/macros/","title":"Macros","text":"<p>TODO: Elaborate</p> <ul> <li>Macros<ul> <li>What is a Rust macro? Gets a TokenStream as input, is able to transform it and outputs a new TokenStream</li> <li>Goal: Reduce code duplication, reduce manually-written code</li> <li>Node<ul> <li>Node declaration <code>#[node(...)]</code> Declare a node<ul> <li>Attached to <code>impl Node {}</code></li> <li>Add <code>struct CycleContext</code><ul> <li>Contains inputs, additional outputs, etc.</li> </ul> </li> <li>Add <code>impl CycleContext { fn new(...) -&gt; CycleContext {} }</code></li> <li>Add <code>struct MainOutputs</code><ul> <li>Contains main outputs</li> </ul> </li> <li>Add <code>impl MainOutputs { fn update(...) {} fn none() {} }</code></li> <li>Modify <code>impl Node {}</code>: Add <code>fn run_cycle() {}</code><ul> <li>Creates <code>CycleContext</code> and <code>MainOutputs</code></li> <li>Call <code>cycle()</code> method of the node</li> </ul> </li> </ul> </li> <li>Inputs<ul> <li>Input <code>#[input(path, data_type, cycler, name)]</code> Get data from this cycle within the current cycler</li> <li>Within control cycler:<ul> <li>Historic Input <code>#[historic_input(path, data_type, name)]</code> Get historic data from control cycler</li> <li>Perception Input <code>#[perception_input(path, data_type, cycler, name)]</code> Get perception data from perception cyclers</li> <li>Persistent State <code>#[persistent_state(path, data_type, name)]</code> Share state between nodes over multiple cycles</li> </ul> </li> <li>Parameter <code>#[parameter(data_type, name, path, on_changed)]</code> Get configuration parameters from the configuration file/via Communication</li> </ul> </li> <li>Outputs<ul> <li>Main Output <code>#[main_output(data_type, name)]</code> Output for dependent nodes, generated in every cycle</li> <li>Additional Output <code>#[additional_output(path, data_type, name)]</code> Optional output that can be enabled/requested from e.g. Communication</li> </ul> </li> </ul> </li> <li><code>require_some!</code> TODO: <code>required</code> flag?<ul> <li>Extracts data from cycle context and returns none for all main outputs if the input was none</li> <li><code>require_some!(...) =&gt; match ... { Some(...) =&gt; ..., None =&gt; return MainOutputs::none() }</code></li> </ul> </li> <li>SerializeHierarchy<ul> <li>Trait<ul> <li>Mostly used by Communication for (de-)serialization</li> <li>Adds support for field paths</li> <li>Allows to (de-)serialize into/from field paths: <code>fn serialize_hierarchy(field_path)</code>, <code>fn deserialize_hierarchy(field_path, data)</code></li> <li>Allows to check if a field paths exists</li> <li>Allows to generate a hierarchy object</li> <li>Implemented for all databases and configuration</li> </ul> </li> <li>Macro <code>#[derive(SerializeHierarchy)]</code><ul> <li>Attached to structs</li> <li>Generates <code>impl SerializeHierarchy for ... { ... }</code><ul> <li>Iterates over all fields and delegates function calls to the fields</li> </ul> </li> </ul> </li> </ul> </li> <li>3rd-party macros: <code>nalgebra::point</code> or <code>nalgebra::matrix</code><ul> <li>Link to 3rd-party documentation</li> </ul> </li> </ul> </li> </ul>"},{"location":"framework/nodes/","title":"Nodes","text":"<p>Nodes usually contain robotics code and are interchangeable components within cyclers. Each node is characterized by a <code>cycle()</code> function which is called in each cycle. The function gets node's inputs as parameters to the <code>cycle()</code> function and returns node's outputs from it. In addition, nodes consist of a state which is perserved between cycles.</p> <p></p> <p>Nodes are normal Rust structs where the struct's fields represent the state and a method called <code>cycle()</code> in the <code>impl</code> of the node represents the <code>cycle()</code> function. This concept allows to write nodes in a very Rusty way. A node may have multiple inputs of different kinds which can be annotated to the node. Here is an example node, but for more information see Macros:</p> <pre><code>pub struct SolePressureFilter { // (1)\nleft_sole_pressure: LowPassFilter&lt;f32&gt;,\nright_sole_pressure: LowPassFilter&lt;f32&gt;,\n}\n#[node(control)] // (2)\n#[parameter(path = low_pass_alpha, data_type = f32)] // (3)\n#[input(path = sensor_data, data_type = SensorData)] // (4)\n#[main_output(data_type = SolePressure)] // (5)\nimpl SolePressureFilter {} // (6)\nimpl SolePressureFilter {\nfn new(context: NewContext) -&gt; anyhow::Result&lt;Self&gt; { // (7)\nOk(Self {\nleft_sole_pressure: LowPassFilter::with_alpha(\n0.0,\n*context.low_pass_alpha, // (8)\n),\nright_sole_pressure: LowPassFilter::with_alpha(\n0.0,\n*context.low_pass_alpha,\n),\n})\n}\nfn cycle(&amp;mut self, context: CycleContext) -&gt; anyhow::Result&lt;MainOutputs&gt; { // (9)\nlet force_sensitive_resistors =\n&amp;require_some!(context.sensor_data).force_sensitive_resistors;\nlet left_sole_pressure = force_sensitive_resistors.left.sum();\nself.left_sole_pressure.update(left_sole_pressure);\nlet right_sole_pressure = force_sensitive_resistors.right.sum();\nself.right_sole_pressure.update(right_sole_pressure);\nOk(MainOutputs {\nsole_pressure: Some(SolePressure {\nleft: self.left_sole_pressure.state(),\nright: self.right_sole_pressure.state(),\n}),\n})\n}\n}\n</code></pre> <ol> <li>Node's state</li> <li>Node declaration with <code>node</code> macro</li> <li>Configuration parameter of type <code>f32</code></li> <li>Input of type <code>SensorData</code></li> <li>Output of type <code>SolePressure</code></li> <li>Empty <code>impl</code> to improve usability of language servers and code linters. If the node declaration would be attached to the <code>impl</code> below, when writing incomplete code, the macros would produce errors. This happens a lot if writing node implementation code.</li> <li>Will be called at construction of the node</li> <li>Use declared configuration parameter. Since it is a reference, we need to dereference it with <code>*</code>.</li> <li>Will be called every cycle</li> </ol> <p>This node consumes the type <code>SensorData</code> as input and produces the output <code>SolePressure</code>. It has two state variables <code>left_sole_pressure</code> and <code>right_sole_pressure</code>.</p> <p>This specification of node inputs and outputs leads to a dependency graph which allows to topologically sort nodes s.t. all dependencies are met before executing the node's <code>cycle()</code>. The <code>build.rs</code> file automatically sorts nodes based on this graph.</p>"},{"location":"framework/overview/","title":"Overview","text":"<p>TODO: Mention unit testing</p> <p>This section explains the framework of our NAO software. The chapters walk through various features in a top-down approach starting with a general overview. More advanced topics are covered later. Here is a short outline of the next chapters:</p> <ul> <li>Directory Structure: Explains the directory structure of the code repository</li> <li>Process EntryPoint: Starts the top-down approach from the <code>main()</code> function of the process</li> <li>Runtime: What does the runtime do to setup and inter-connect all subcomponents?</li> <li>Cyclers: How do cyclers run the robotics nodes?</li> <li>Nodes: What are nodes and how are they implemented?</li> <li>Databases &amp; Types: How can data be shared between cyclers and the framework?</li> <li>Parameters: How does the framework provide configuration parameters to nodes?</li> <li>Communication: What is communication and how is it able to communicate between framework and nodes?</li> <li>Hardware Interface: How is the hardware abstracted away for the different target platforms?</li> <li>Thread Communication: Which concepts and features exist to enable thread-safe communication between subcomponents?</li> <li>Filtering: How to interleave historic data in filters in an multi-threaded software?</li> <li>Macros: What macros exist that ease the development and how do they work?</li> <li>Error Handling: Which kinds of error handling concepts are supported and which to choose when?</li> </ul> <p>The framework provides the fundamentals needed to execute robotics specific code. It has a modular design to allow for convenient development and replacement of individual nodes. The framework consists of four fundamental components:</p> <ul> <li>Runtime: Encapsulates all subcomponents by starting and initializing them</li> <li>Hardware Interface: Abstracts hardware away and is the interaction point for cyclers with the outside world</li> <li>Cyclers: Cycle through nodes, process data from hardware and produce outputs (see e.g. control or vision_top)</li> <li>Communication: Exchanges data between framework and other resources e.g. file system and network</li> </ul> <p></p>"},{"location":"framework/parameters/","title":"Parameters","text":"<p>TODO: Elaborate</p> <ul> <li>Parameters<ul> <li>Parameters contains types</li> <li>Loaded from filesystem</li> <li>Location \"Overwriting\" &amp; Robot \"Overwriting\"</li> </ul> </li> </ul>"},{"location":"framework/process_entrypoint/","title":"Process Entrypoint","text":"<p>The HULKs robotic control software can be compiled for multiple build targets e.g. NAO and Webots. Each build target results in a executable which is either executed directly on the NAO or on the development machine. All executables define a <code>main()</code> function as entrypoint for the robotic control software, see <code>src/bin/</code> in the code. The following sections explain the first setup steps done in the <code>main()</code> function for the major build targets NAO and Webots. The final sections cover the behavior simulator entrypoint briefly.</p>"},{"location":"framework/process_entrypoint/#shutdown-and-cancellationtoken","title":"Shutdown and CancellationToken","text":"<p>The <code>main()</code> functions for the NAO and Webots targets register shutdown handlers via the Rust crate ctrlc. These shutdown handlers react on the Linux signals <code>SIGINT</code> and <code>SIGTERM</code> to call <code>CancellationToken::cancelled()</code> which cancels the <code>CancellationToken</code> on signal receival. The <code>CancellationToken</code> is a synchronization primitive which is shared with the whole framework and robotics code to allow to shutdown all subcomponents from any location. Several places listen for the <code>cancelled()</code> event and terminate on cancellation. Beside cancelling the <code>CancellationToken</code> on Linux signals, error conditions within the robotic control software can trigger a cancellation as well. This concept allows to shutdown gracefully in any case of error or termination request.</p>"},{"location":"framework/process_entrypoint/#hardware-interface-runtime","title":"Hardware Interface &amp; Runtime","text":"<p>On NAO and in Webots the robotic control software needs access to the hardware or simulator interface. The hardware interface provides an abstract way to interact with the underlying backend. The <code>main()</code> function first initializes the hardware interface and then constructs the runtime with it. See Hardware Interface for more information about what the hardware interface initializes. At the end, the runtime is started. The <code>main()</code> function then waits for termination of the runtime which then concludes the process execution.</p>"},{"location":"framework/process_entrypoint/#behavior-simulator","title":"Behavior Simulator","text":"<p>The behavior simulator is a special build target which only initializes and starts a subset of the robotic control software. It is intended to be executed on the development machine. Cancellation and hardware interfaces are not needed and are therefore omitted from initialization in <code>main()</code>. Instead, the behavior simulator parses command line arguments and dispatches the behavior simulation.</p>"},{"location":"framework/runtime/","title":"Runtime","text":"<p>The runtime is the component in the robotic control software that encapsulates all subcomponents e.g. the hardware interface, cyclers, and communication. Here is a more detailed overview extending the drawing from Overview:</p> <p></p> <p>This section and following ones will cover this drawing in more detail. Many dataflow connections are still left out to improve readability.</p> <p>The runtime is constructed with an already existing and initialized hardware interface. The runtime contains all subcomponents and therefore is in charge to construct them. Subcomponents require to be interconnected with each other. The runtime therefore creates all necessary communication channels and buffers that are shared between the subcomponents. More details on the connections between cyclers and communication are given in Communication.</p> <p>The communication subcomponent and each cycler are executed in separate threads which are started. The next section Cyclers talks more about the cyclers.</p>"},{"location":"framework/thread_communication/","title":"Thread Communication","text":"<p>TODO: Elaborate</p> <ul> <li>Buffering/Thread Communication/Channels<ul> <li>Tokio CancellationToken</li> <li>n-tuple Buffer<ul> <li>Related to Triple Buffer</li> <li>Guarantees, Assumptions</li> </ul> </li> <li>Tokio channels</li> <li>Channel flow diagram (mostly Cycler&lt;-&gt;Cycler and Cycler&lt;-&gt;Communication)</li> </ul> </li> </ul>"},{"location":"operating_system/home_directory/","title":"Home Directory","text":"<p>The home directory (<code>/home/nao/</code>) is overlayed with a mount to the <code>/data</code> partition (see Partitioning).</p> <p>When flashing the robot and uploading the hulk binary, the home directory structure looks as follows:</p> <pre><code>.\n|-- hulk\n|   |-- bin\n|   |   `-- hulk\n|   |-- etc\n|   |   |-- parameters\n|   |   |   `-- *.json\n|   |   |-- motions\n|   |   |   `-- *.motion2\n|   |   |-- neural_networks\n|   |   |   `-- *.hdf5\n|   |   |-- poses\n|   |   |   `-- *.pose\n|   |   `-- sounds\n|   |       `-- *.ogg\n|   `-- logs\n|       |-- hulk-1667906932.err\n|       |-- hulk-1667906932.out\n|       |-- hulk.err -&gt; /home/nao/hulk/logs/hulk-1667906932.err\n|       `-- hulk.out -&gt; /home/nao/hulk/logs/hulk-1667906932.out\n`-- robocup.conf\n</code></pre> <p>The <code>./robocup.conf</code> file is required to start the LoLA service in robocupper mode. All files related to the hulk service and binaries are stored in the subdirectory <code>hulk</code> and mirrors the files of the directory structure of the development repository (Directory Structure).</p>"},{"location":"operating_system/hula/","title":"HULA","text":"<p>TODO</p>"},{"location":"operating_system/linux/","title":"Linux","text":"<p>The Nao uses a Linux 5.4 real time kernel for intel processors (linux-intel/preempt-rt).</p> <p>Most of the kernel configuration is done by the <code>meta-intel</code> layer for yocto. Special modifications for the Nao robot are contained in the <code>meta-nao</code> layer and mainly consist of patches and kernel modules by aldebaran for chestboard communication.</p>"},{"location":"operating_system/overview/","title":"Overview","text":"<p>TODOs:</p> <ul> <li>Chapter introduction</li> <li>HULA</li> </ul>"},{"location":"operating_system/overview/#outline","title":"Outline","text":"<ul> <li>Partitioning</li> <li>Home Directory</li> <li>Linux</li> <li>WiFi</li> <li>HULA</li> </ul>"},{"location":"operating_system/partitioning/","title":"Partitioning","text":"<p>The Nao uses a single flash storage device for main storage purposes. After a successfully flashing the robot with the HULKs OS, this storage device is recogniced as <code>/dev/mmcblk1</code>. The device counts 4 separate partitions.</p> <pre><code>NAME          SIZE MOUNTPOINTS\nmmcblk1      29.1G\n|-mmcblk1p1   128M /media/internal\n|-mmcblk1p2    64M\n|-mmcblk1p3   3.8G /\n`-mmcblk1p4  25.1G /data\n</code></pre>"},{"location":"operating_system/partitioning/#softbank-partition-mmcblk1p1","title":"Softbank partition <code>mmcblk1p1</code>","text":"<p>The first partition is called 'internal' and is used by softbank binaries and during the flashing. The partition is mounted by default at <code>/media/internal</code> and is required to be mounted when using LoLA or HAL. During standard use, this partition is not accessed by HULKs binaries.</p> <p>Softbank uses this partition to store general information about the robot, such as IDs. The aldebaran script <code>/opt/aldebaran/head_id</code> for example uses the file <code>/media/internal/DeviceHeadInternalGeode.xml</code> to query the id of the head.</p>"},{"location":"operating_system/partitioning/#efi-partition-mmcblk1p2","title":"EFI partition <code>mmcblk1p2</code>","text":"<p>The second partition is the EFI boot partition and not mounted by default. To inspect the EFI files mount this partition:</p> <pre><code>sudo su\nmount /dev/mmcblk1p2 /mnt/\n# inspect files at /mnt/\n</code></pre>"},{"location":"operating_system/partitioning/#root-partition-mmcblk1p3","title":"Root partition <code>mmcblk1p3</code>","text":"<p>The third partition is the root partition. This partition is created and managed by the yocto configuration and usually not inteded to be modified at runtime.</p>"},{"location":"operating_system/partitioning/#data-partition-mmcblk1p4","title":"Data partition <code>mmcblk1p4</code>","text":"<p>The fourth and last partition is for runtime data storage. It is mounted to <code>/data</code> by default.</p> <p>When first booting up the system, the two system units <code>data-format</code> and <code>data-skeleton</code> are responsible of setting up the partition and directory structure. The <code>data-format</code> unit is run once before mounting the partition to create a new filesystem and disables itself afterwards. The <code>data-skeleton</code> unit is run every startup and provides a directory structure for following overlay mounts.</p>"},{"location":"operating_system/partitioning/#home-directory-homenao","title":"Home directory <code>/home/nao</code>","text":"<p>The home directory is used for custom user code and also for storing and executing the <code>hulk</code> binary. It is an overlay mount specified in the <code>/etc/fstab</code>:</p> <pre><code>[...]\noverlay /home/nao overlay lowerdir=/home/nao,upperdir=/data/home/nao,workdir=/data/.work-home-nao 0 0\n[...]\n</code></pre>"},{"location":"operating_system/wifi/","title":"WiFi","text":"<p>The WiFi is supplied by a Qualcomm Atheros AR9462 and configured via the iNet Wireless Daemon (iwd). For more information on iwd visit their documentation.</p>"},{"location":"operating_system/wifi/#iwd-configuration","title":"<code>iwd</code> Configuration","text":"<p>The iwd service can be manually configured using the command line interface tool <code>iwctl</code>. For persistent configuration iwd stores <code>*.psk</code> files for every known SSID at <code>/var/lib/iwd/</code>. The yocto distribution installs those <code>*.psk</code> files for the network SSIDs SPL_A to SPL_F.</p> <pre><code>[Security]\nPassphrase=Nao?!Nao?!\n\n[Settings]\nAutoConnect=false\n</code></pre> <p>Automatic connection is disabled to prevent the Nao to connect to any SPL network in range. If iwd was tasked to connect to a network once, it tries to reconnect to that same SSID until the daemon is instructed to disconnect.</p> <p>The iwd is also able configure IP settings and run DHCP. This is called Network Configuration and disabled via the <code>/etc/iwd/main.conf</code>. IP configuration is and done by systemd-networkd.</p> <pre><code>[General]\nEnableNetworkConfiguration=false\n</code></pre>"},{"location":"operating_system/wifi/#ip-configuration","title":"IP Configuration","text":"<p>The Nao's IP address is derived from the robots id number in the <code>../setup/nao_image_and_sdk.md</code>. This follows the pattern <code>10.{Interface}.{TeamNumber}.{NaoNumber}</code>. For the robot 22 of team HULKs this is <code>10.0.24.22</code> on the wireless interface and <code>10.1.24.22</code> on the wired interface.</p> <p>Responsible for the configuration is the systemd unit <code>network-config</code> running the <code>/usr/sbin/configure_network</code> script once per boot. This script is calculating the IP configuration based on the entries in the <code>/etc/id_map.json</code> and generates systemd network configuration files at <code>/etc/systemd/network/80-wlan.network</code> and <code>/etc/systemd/network/80-wired.network</code>.</p>"},{"location":"robotics/overview/","title":"Overview","text":"<p>TODO: Elaborate</p>"},{"location":"robotics/overview/#perception","title":"Perception","text":"<ul> <li>Filters</li> <li>SPL Network (GameController communication, Team communication)</li> <li>Vision</li> <li>Whistle Detection/Audio</li> </ul>"},{"location":"robotics/overview/#behavior","title":"Behavior","text":"<ul> <li>World state -&gt; Actions -&gt; MotionCommand</li> </ul>"},{"location":"robotics/overview/#motion","title":"Motion","text":"<ul> <li>Step planning</li> <li>Walking</li> <li>Kicking</li> <li>...</li> </ul>"},{"location":"robotics/miscellaneous/create_urdf/","title":"Create URDF and PROTO for NAOv6","text":"<p>For Webots we need a PROTO file which should contain 3D models and the scene graph of the NAOv6. The only source is a URDF from http://doc.aldebaran.com/2-8/family/nao_technical/kinematics_naov6.html#naov6-urdf-files. Meshes in OGRE mesh format can be found in e.g. the \"C++ SDK\" from https://developer.softbankrobotics.com/nao6/downloads/nao6-downloads-linux (in <code>share/alrobotmodel/meshes</code>). The URDF and meshes need to be converted to Webots PROTO.</p> <p>Download and build target <code>OgreXMLConverter</code> in https://github.com/OGRECave/ogre (e.g. <code>cmake --build build --target OgreXMLConverter</code>). <code>OgreXMLConverter</code> is able to convert OGRE mesh files into XML files containing the raw vertices and face vector indices. The resulting XML files can be converted into binary STL files with the script <code>xml_to_stl.py</code>.</p> <p>The script above generates multiple STL files for each submesh contained in the XML file. This allows to set different materials in the URDF. The material's name is included in the STL filename. Since the URDF only references the old mesh files it needs to be adapted to contain multiple <code>&lt;visual&gt;</code> sections with same translation and rotation but with different STL mesh files and materials (<code>package://</code> prefixes can be dropped).</p> <p>Cameras can be added with e.g.:</p> <pre><code>&lt;gazebo reference=\"CameraTop\"&gt;\n&lt;sensor type=\"camera\" name=\"CameraTop\"&gt;\n&lt;camera name=\"CameraTop\"&gt;\n&lt;horizontal_fov&gt;0.982122222&lt;/horizontal_fov&gt;\n&lt;image&gt;\n&lt;width&gt;640&lt;/width&gt;\n&lt;height&gt;480&lt;/height&gt;\n&lt;format&gt;R8G8B8A8&lt;/format&gt;\n&lt;/image&gt;\n&lt;/camera&gt;\n&lt;/sensor&gt;\n&lt;/gazebo&gt;\n</code></pre> <p>And an IMU with e.g.:</p> <pre><code>&lt;gazebo reference=\"Accelerometer\"&gt;\n&lt;plugin filename=\"libgazebo_ros_imu.so\"&gt;\n&lt;topicName&gt;IMU&lt;/topicName&gt;\n&lt;/plugin&gt;\n&lt;/gazebo&gt;\n</code></pre> <p>The URDF is as complete as it can get. The URDF with STLs can be converted with https://github.com/cyberbotics/urdf2webots to a PROTO file. <code>urdf2webots</code> only converts a subset of sensors (https://github.com/cyberbotics/urdf2webots/blob/6630d9778af064983f97ef1b2ea87f91c1efb48b/urdf2webots/parserURDF.py#L986-L1080) and has only limited conversion capabilities for meshes etc. At this point the PROTO file needs to be finalized manually.</p> <p>Cameras are wrongly oriented and need to be rotated: Both camera's rotation needs to be <code>rotation 0.577350 -0.577350 -0.577350 2.093333333</code>.</p> <p>If not setting all initial joint angles to zero, the robot seems to have random initial angles in Webots. Therefore specify <code>--init-pos=\"[0.0, 0.0, 0.0, ..., 0.0, 0.0]\"</code> to <code>urdf2webots</code> (the amount of <code>0.0</code> corresponds to the number of joints, e.g. 130).</p>"},{"location":"robotics/motion/motion_files/","title":"Motion Files","text":""},{"location":"robotics/perception/vision/","title":"Vision","text":"<p>TODO: Mention all nodes or just the important ones? Nodes of questionable importance:</p> <ul> <li>Field color detection</li> <li>Camera matrix provider</li> </ul> <p>TODO: Add images</p> <p>The vision cycler runs twice in two separate threads to process the images from the top and bottom camera in parallel.</p> <p>Image resolution is determined by the hardware interface, but is currently set to 640x480 pixels for performance reasons. Most of the vision pipeline happens on a segmented version of the image for the same reason.</p> <p>Each cycler instance waits for the hardware interface to deliver it's respective camera image and then begins executing the nodes listed below.</p>"},{"location":"robotics/perception/vision/#camera-matrix-provider","title":"Camera Matrix Provider","text":""},{"location":"robotics/perception/vision/#field-color-detection","title":"Field Color Detection","text":""},{"location":"robotics/perception/vision/#image-segmenter","title":"Image Segmenter","text":"<p>The first major node in the vision pipeline is the image segmenter. It iterates through the image and merges vertically adjacent pixels that are similar. This reduces the amount of elements subsequent nodes have to process. Instead of 480 pixels, each vertical scan line is reduced to just a dozen or so segments, depending on the image. A stride can be set to only generate scanlines for every n-th pixel column. Furthermore, segments which are above the horizon or overlap the robots limbs are discarded, resulting in a sparse image.</p> <p>Each segment contains it's location, color, edge types, and a pre-calculated classification of field color intensity.</p>"},{"location":"robotics/perception/vision/#field-border-detection","title":"Field Border Detection","text":"<p>Estimates the location of the upper field border in the image by finding the first pixels from the top that are roughly field-colored and fitting a line through them.</p>"},{"location":"robotics/perception/vision/#segment-filter","title":"Segment Filter","text":"<p>The image segments are further reduced by removing all segments that are considered field color to only preserve relevant features. Segments above the field border are also removed.</p>"},{"location":"robotics/perception/vision/#line-detection","title":"Line Detection","text":"<p>Using the filtered segments, field lines are detected by looking for white segments of appropriate length. For each segment the brightness gradient at each end is calculated using the Sobel operator. The segment is discarded if the gradients are not sufficiently steep upwards and downwards, i.e. the segment borders do not lie on opposite flanks of a field line.</p> <p>The center of each remaining segment is then used in a RANSAC line fitting algorithm. Found lines are projected onto the ground and then checked against those found previously to see if they are either parallel or orthogonal to each other.</p> <p>TODO: Why check parallelism and orthogonality? What do we do with this information?</p>"},{"location":"robotics/perception/vision/#perspective-grid-candidate-provider","title":"Perspective Grid Candidate Provider","text":"<p>This node generates candidates for the Ball Detection. Starting from the bottom of the image, rows of circles are generated where the circle size matches the projected ball in the row's center. Candidates are only generated when the center of at least one filtered segment is inside the candidate circle's bounding box.</p>"},{"location":"robotics/perception/vision/#ball-detection","title":"Ball Detection","text":"<p>For each perspective grid candidate a series of artifical neural networks is used to determine whether it contains a ball as well as the balls location and radius. First, a slightly larger sample centered around the candidate is extracted from the raw image. This sample is scaled up or down to 32x32 pixels, regardless of the size in the raw image.</p> <p>The first neural network to run on the image is called the \"preclassifier\", which is a small but cheap model to quickly filter out candidates that are clearly not a ball.</p> <p>If the preclassifier claims to have found a ball, a larger and more accurate network, the \"classifier\", is executed to decide whether the candidate contains a ball or not.</p> <p>Once the classifier finds a ball, a third neural network, the \"positioner\", is used to determine the location and size of the ball within the sample. These values are then transformed back into the coordinate frame of the image and then projected onto the field to determine the final location of the detected ball.</p> <p>TODO: Clustering</p> <p></p> <p>TODO: Implement this view in twix and update screenshot</p> <p>Debug view showing:</p> <ul> <li>blue circle: candidates from the perspective grid</li> <li>green circle: positioner network output</li> <li>white circle: clustered ball location</li> <li>red circle: current ball model, see filters</li> <li>black text: preclassifier confidence</li> </ul>"},{"location":"robotics/perception/vision/#robot-detection","title":"Robot Detection","text":"<p>Warning: This node is still work in progress.</p> <p>For detecting robots, a clustering algorithm runs through each vertical scanline of the filtered image segments, ignoring segments that have been previously used by the ball detection or line detection. The last (bottom most) cluster in each scanline is then projected to the ground and clustered first using the score-weighted distance and then again using cones.</p> <p>TODO: What does this mean? Why do we do this?</p>"},{"location":"setup/main_setup/","title":"Main Setup and Compiling for Webots","text":"<p>This section will guide you through the installation of dependencies and compiling the code for the Webots simulator. We recommend using Arch Linux or one of it's derivatives such as Manjaro.</p>"},{"location":"setup/main_setup/#installing-dependencies","title":"Installing Dependencies","text":"<p>Some packages are required to be installed before you can compile and run our code. Use your distribution's package manager to install the following dependencies:</p> Arch Linux/ManjaroUbuntuFedora <ol> <li> <p>Install dependencies</p> <p><pre><code>yay -S git git-lfs base-devel rustup rsync cmake clang hdf5 python webots\n</code></pre> <code>yay</code> is used because <code>webots</code> is an AUR package. Optionally substitute <code>yay</code> with your favorite AUR helper.</p> </li> <li> <p>Install rust toolchain</p> <pre><code>rustup default stable\n</code></pre> </li> </ol> <ol> <li> <p>Install dependencies</p> <pre><code>sudo apt install git git-lfs build-essential libssl-dev pkg-config libclang-dev rsync cmake libhdf5-dev python3 libasound2-dev libluajit-5.1-dev libudev-dev\n</code></pre> </li> <li> <p>Install Webots     Download webots from https://cyberbotics.com/ the XXXX.deb file and install it with</p> <pre><code>sudo dpkg -i XXXX.deb\n</code></pre> </li> <li> <p>Install rust toolchain</p> <p>Visit https://rustup.rs/ for up to date instructions.</p> </li> </ol> <ol> <li> <p>Install dependencies</p> <pre><code>sudo dnf install git git-lfs hdf5-devel clang-devel rsync cmake python luajit-devel libudev-devel\n</code></pre> </li> <li> <p>Install Webots</p> <p>At the moment there are no official Fedora packages, but the archive for Ubuntu has worked out fine in our experience. Download webots from https://cyberbotics.com/ the XXXX.tar.bz (Ubuntu Archive) file and install to a local directory.</p> <pre><code>mkdir ~/tools/     # example install location\ncd ~/tools\ntar -xf ...tar.bz  # creates a directory named `webots`\n# symlink to be accessible from the command line\nln -s ~/tools/webots/webots ~/.local/bin/webots\n</code></pre> </li> <li> <p>Install rust toolchain</p> <p>Visit https://rustup.rs/ for up to date instructions.</p> </li> </ol>"},{"location":"setup/main_setup/#acquiring-the-code","title":"Acquiring the code","text":"<p>Clone our HULKs/hulk repository from GitHub:</p> <pre><code>git clone git@github.com:HULKs/hulk\n</code></pre>"},{"location":"setup/main_setup/#compiling-for-webots","title":"Compiling for Webots","text":"<p>In the root of our repository is a script called <code>pepsi</code>. See pepsi for details. Simply execute the build command in the repository root to build a binary for use with Webots. This will first build the pepsi binary and then start the build process.</p> <pre><code>./pepsi build\n</code></pre>"},{"location":"setup/main_setup/#running-webots","title":"Running Webots","text":"<p>Once the compilation step is complete, open webots and load the scene at <code>webots/worlds/penalized.wbt</code> from the repository.</p>"},{"location":"setup/main_setup/#running-webots-in-external-mode","title":"Running Webots in external Mode","text":"<p>To not be forced to reload the scene in Webots when rebuilding the controller, you can run in webots <code>webots/worlds/penalized_extern.wbt</code> and starting the controller with:</p> <pre><code>./pepsi run\n</code></pre>"},{"location":"setup/main_setup/#running-behavior-simulator","title":"Running Behavior Simulator","text":"<p>To be able to run the current behavior simulator files, you have to install lua <code>\u00ecnspect</code> package, either by downloading and saving it to the lua path (e.g., you hulk repo) or by using a lua package manager.</p> <p>Afterwards you can run the simulator by executing the following command in your hulk project root folder: <pre><code>cargo run --manifest-path=tools/behavior_simulator/Cargo.toml tests/behavior/golden_goal.lua\n</code></pre> The results can be inspected in twix.</p>"},{"location":"setup/nao_image_and_sdk/","title":"NAO Image &amp; SDK","text":"<p>TODO: decide whether to backtick all \"meta-nao\", \"meta-hulks\", \"kas\", \"BitBake\" names TODO: \"code release\" or \"code-release\" or \"coderelease\"? TODO: Set up id map json first TODO: Change team number in meta-hulks</p> <p>The HULKs use the Yocto Project for creating flashable OPN images for the NAO and a corresponding software development kit (SDK) for local development targeting the NAO. The SDK contains a full cross-compilation toolchain that is self-contained and can be easily used on development machines.</p>"},{"location":"setup/nao_image_and_sdk/#use-an-existing-yocto-sdk-with-the-hulks-code","title":"Use an Existing Yocto SDK with the HULKs Code","text":"<p>You can just use pepsi to compile and upload to a booted NAO. Within the HULKs repository, use the following command to e.g. upload to NAO 42:</p> <pre><code>./pepsi upload 42\n</code></pre> <p>Pepsi will automatically download the SDK from the BigHULK (internal server only accessible in the HULKs lab network) or GitHub and ask you to install it during the compilation process.</p>"},{"location":"setup/nao_image_and_sdk/#image-sdk-creation","title":"Image &amp; SDK Creation","text":"<p>The Yocto Project leverages BitBake as task execution engine and offers an abstraction layer to modify and extend existing build configurations. Combined with OpenEmbedded, the entire worktree is structured in several layers (the HULKs use the meta-nao and meta-hulks layers).</p>"},{"location":"setup/nao_image_and_sdk/#setup-of-the-working-directory","title":"Setup of the Working Directory","text":"<p>For creating the image and SDK, make sure there is at least 100 GB empty disk space available. Start by cloning the code (if not done before) and setting up a Yocto working directory. This working directory will contain the layers HULKs/meta-nao and meta-hulks, a script for running BitBake commands, and the HULKs nao repository. It will be called <code>yocto</code>. The new <code>yocto</code> working directory must have at least 100 GB of empty space available and should not be part of a Git repository.</p> <pre><code>mkdir yocto/\ncd yocto/\n</code></pre> HULKs MembersNon HULKs Members <p>HULKs members need the HULKs/hulk repository, and the HULKs/meta-nao and HULKs/meta-hulks layer. The rest should already be set up.</p> <pre><code># working directory is still `yocto`\ngit clone git@github.com:HULKs/hulk\ngit clone git@github.com:HULKs/meta-nao\ngit clone git@github.com:HULKs/meta-hulks\n</code></pre> <p>Non HULKs members need the HULKs/meta-nao layer and the meta-hulks layer from HULKs/CodeRelease (in the subdirectory <code>yocto/meta-hulks</code>).</p> <pre><code># working directory is still `yocto`\ngit clone git@github.com:HULKs/HULKsCodeRelease\nmv HULKsCodeRelease hulk\n#ln -s nao/yocto/meta-hulks meta-hulks\n#sed -i 's|path: \"patches|path: \"yocto/meta-hulks/patches|' meta-hulks/kas-project.yml\ncp -r nao/yocto/meta-hulks meta-hulks\ngit clone git@github.com:HULKs/meta-nao\n</code></pre> <p>During the HULKs code release generation, some cryptographic keys are replaced. If you want to e.g. connect to a NAO via SSH the following steps need to be done to recreate the keys:</p> <pre><code># working directory is still `yocto`\nssh-keygen -t ed25519 -C nao@hulk -f nao/scripts/ssh_key\n# Answer `y` when asked to overwrite\ncat nao/scripts/ssh_key.pub &gt; meta-hulks/recipes-connectivity/openssh/openssh/authorized_keys\n</code></pre> <p>If you wondered, as a non HULKs member you don't need the <code>meta-hulks/ssh-dir</code> populated with keys.</p> <p>In addition to the SSH keys, also the NAO hardware IDs and wireless network configurations need to be adjusted. The hardware IDs can be configured in <code>meta-hulks/recipes-hulks/network-config/network-config/id_map.json</code>. Wireless networks can be configured at <code>meta-hulks/recipes-conf/nao-wifi-conf/nao-wifi-conf/*.psk</code> (iwd is used). If networks are added/removed or names change, the recipe <code>meta-hulks/recipes-conf/nao-wifi-conf.bb</code> also needs adjustmenst.</p> <p>For project setup the siemens/kas framework is used. To setup kas use the containerized version (podman or docker) via the kas-container script and store it inside the <code>yocto</code> directory.</p> <pre><code>wget https://github.com/siemens/kas/raw/master/kas-container\nchmod +x kas-container\n</code></pre> <p>Alternatively setup kas via a python-pip installation, follow the installation steps in the user guide.</p> <p>The meta-hulks layer ships a <code>kas-project.yml</code> project description file. This file defines the project structure kas has to setup for the Yocto build phase. The next step is to download all the referenced repositories in the <code>kas-project.yml</code>.</p> <pre><code>./kas-container checkout meta-hulks/kas-project.yml\n</code></pre> <p>The NAO v6 uses LoLA and HAL for communication with the chestboard. All these binaries and libraries necessary to operate the NAO properly are shipped with the <code>.opn</code> RoboCupper image and are not included in this repository. For HULKs members contact our dev-leads and for non HULKs members contact the RoboCup SPL Technical Committee to get this image. To extract the necessary binaries the <code>extract_binaries.sh</code> script is used. This script fetches all binaries from inside the RoboCupper image and collects them in an archive for the upcoming build phase. To generate the archive containing the aldebaran binaries run (with root privileges):</p> <pre><code>cd meta-nao/recipes-support/aldebaran/\nmkdir -p aldebaran-binaries\n./extract_binaries.sh -o aldebaran-binaries/aldebaran_binaries.tar.gz nao-2.8.5.11_ROBOCUP_ONLY_with_root.opn\n</code></pre>"},{"location":"setup/nao_image_and_sdk/#starting-a-build-shell","title":"Starting a Build Shell","text":"<p>kas is able to start a shell inside of the build environment. The <code>kas-project.yml</code> of meta-hulks needs to be referenced:</p> <pre><code># working directory is `yocto`\n./kas-container shell meta-hulks/kas-project.yml\n</code></pre> <p>All BitBake and Devtool commands shall be executed from this shell.</p>"},{"location":"setup/nao_image_and_sdk/#preparing-the-build","title":"Preparing the Build","text":"<p>The NAO image contains the HULA binary (TODO: link to HULA) which is built from HULKs/hulk or HULKs/CodeRelease (depending on whether you are a HULKs member or not). The HULA source code is located in <code>tools/hula</code>. The meta-hulks layer is set up to clone the private HULKs/hulk repository and check out a specific version. This only works if the kas-container has SSH correctly set up and uses a SSH key that has access to the repository. Ensure that the SSH private key has appropriate permissions, usually <code>600</code>. Most often it is easier to clone the repository manually and point BitBake to use it. The following command can be executed within the build environment to do that:</p> <pre><code>devtool modify --no-extract hula /work/nao\n</code></pre> <p>This must be executed at any restart of the build shell.</p>"},{"location":"setup/nao_image_and_sdk/#building-the-image","title":"Building the Image","text":"<p>Inside of the build shell, the following command will build the NAO image. The initial build may take multiple hours depending on your hardware and internet access. BitBake provides advanced caching of the build artifacts which means that future builds are done in minutes depending on the changes. The cache relies in the <code>build/sstate-cache</code> which can be copied from another build directory or shared between machines ( see Yocto Documentation about Shared State Cache). To build the image run the following command in the build shell:</p> <pre><code>bitbake nao-image\n</code></pre> <p>This generates and executes all necessary tasks and targets to construct a proper <code>.opn</code> file. The initial build phase might take several hours depending on the performance of your build machine and your internet connection. BitBake uses a very elaborated caching strategy to speed up following builds of targets. Thus small changes afterwards might only take a few minutes.</p> <p>As soon as the build has successfully finished, the image can be deployed. After BitBake ran all tasks up to nao-image, a new <code>.opn</code> file is generated in <code>build/tmp/deploy/images/nao-v6/nao-image-HULKs-OS-[...].ext3.gz.opn</code>. The image can now be flashed to a NAO as described in the NAO setup section.</p> <p>Make sure a RoboCupper image has been flashed before flashing the first Yocto image, since the latter does not flash the chestboard (which needs up-to-date software). This step is not required for flashing subsequent Yocto images.</p>"},{"location":"setup/nao_image_and_sdk/#building-the-sdk","title":"Building the SDK","text":"<p>To be able to compile the HULKs robotics code targeting the NAO platform, the code needs to be cross compiled for the NAO target. Within the build shell, the following command will build the SDK:</p> <pre><code>bitbake -c populate_sdk nao-image\n</code></pre> <p>This build phase may take several hours. After a successful build, the SDK is located at <code>build/tmp/deploy/sdk/HULKs-OS-toolchain-[...].sh</code>. To install the SDK run the script and follow the instructions. Afterwards, you are able to source the build environment and use the respective cross compilers.</p>"},{"location":"setup/nao_image_and_sdk/#advanced-upgrade-other-yocto-layers","title":"Advanced: Upgrade other Yocto Layers","text":"<p>The Yocto Project and the Poky reference distribution provide a Linux kernel, userland programs, libraries, and other tooling. All these things are updated in the regular Yocto releases. To ensure deterministic builds the HULKs freeze versions of all used layers in the <code>kas-project.yml</code> files of meta-nao and meta-hulks.</p>"},{"location":"setup/nao_image_and_sdk/#advanced-upgrade-imagesdk-versions-and-semantic-versioning","title":"Advanced: Upgrade Image/SDK Versions and Semantic Versioning","text":"<p>The HULKs use semantic versioning for the Yocto images and SDKs. This means that versions are increased depending on the severity of changes. The following policy exists for the HULKs:</p> <ul> <li>Both images and SDKs have major, minor, and patch version numbers (e.g. 4.2.3)</li> <li>Images and SDKs with the same major and minor version number are compatible with each other</li> <li>Major changes, refactorings, implementations result in the increase of the major version number</li> <li>Minor changes, additions and iterations result in the increase of the minor version number</li> <li>Changes in the image that do not require SDK recreation, result in the increase of the patch version number (which only requires to create a new image)</li> </ul> <p>Before building new images, the version number needs to be set in <code>meta-hulks/conf/distro/HULKsOS.conf</code>. Only change the <code>DISTRO_VERSION</code>, the <code>SDK_VERSION</code> is automatically derived from the <code>DISTRO_VERSION</code>.</p> <p>Once a new image and/or SDK is released, pepsi needs to know the new version numbers. Therefore update the variables <code>OS_VERSION</code> and/or <code>SDK_VERSION</code> in <code>crates/constants/src/lib.rs</code>. Successive builds with pepsi will use the new version.</p>"},{"location":"setup/nao_image_and_sdk/#advanced-upgrade-rust-version","title":"Advanced: Upgrade Rust Version","text":"<p>Since upgrading the Rust version often requires manual steps, this section describes the approach on how to upgrade and generate the needed patch files. These instructions can be followed e.g. if a new Rust version is available and a new image/SDK should be created with this new version. Users that just want to use the current version that we upgraded to should skip this section. The latest patch set for is included in the meta-hulks layer (in <code>patches/</code>) or HULKs code release (in <code>yocto/meta-hulks/patches/</code>).</p> <p>Rust is provided by the poky repository. The recipes are located in <code>meta/recipes-devtools/{cargo,rust}</code>. The following steps are high-level instructions on how to modify the poky repository. A patch file can be created after applying these instructions and saved to the corresponding meta-hulks layer.</p> <ul> <li>Set new version in the <code>RUSTVERSION</code> variable in <code>poky/meta/conf/distro/include/tcmode-default.inc</code></li> <li>Rename files (to new version) in <code>poky/meta/recipes-devtools/cargo/</code></li> <li>Rename files (to new version) in <code>poky/meta/recipes-devtools/rust/</code></li> <li>Some LLVM benchmarks are built and run during the compilation which often results in errors.     Therefore, it is a good idea to just exclude them by appending <code>-DLLVM_BUILD_BENCHMARKS=OFF</code> and <code>-DLLVM_INCLUDE_BENCHMARKS=OFF</code> to the <code>EXTRA_OECMAKE</code> variable in <code>poky/meta/recipes-devtools/rust/rust-llvm.inc</code>.</li> <li>Set new version in the <code>RS_VERSION</code> and <code>CARGO_VERSION</code> variable in <code>poky/meta/recipes-devtools/rust/rust-snapshot.inc</code></li> <li>Update the checksums in <code>poky/meta/recipes-devtools/rust/rust-snapshot.inc</code> for the NAO architecture <code>x86_64</code><ul> <li>Download the files in your command line (example for Rust version 1.63): <pre><code>RS_VERSION=\"1.63.0\"\nCARGO_VERSION=\"1.63.0\"\nRUST_BUILD_ARCH=\"x86_64\"\nRUST_STD_SNAPSHOT=\"rust-std-${RS_VERSION}-${RUST_BUILD_ARCH}-unknown-linux-gnu\"\nRUSTC_SNAPSHOT=\"rustc-${RS_VERSION}-${RUST_BUILD_ARCH}-unknown-linux-gnu\"\nCARGO_SNAPSHOT=\"cargo-${CARGO_VERSION}-${RUST_BUILD_ARCH}-unknown-linux-gnu\"\nwget \"https://static.rust-lang.org/dist/${RUST_STD_SNAPSHOT}.tar.xz\"\nwget \"https://static.rust-lang.org/dist/${RUSTC_SNAPSHOT}.tar.xz\"\nwget \"https://static.rust-lang.org/dist/${CARGO_SNAPSHOT}.tar.xz\"\n</code></pre></li> <li>Generate the checksums in the same terminal:     <pre><code>sha256sum ${RUST_STD_SNAPSHOT}.tar.xz ${RUSTC_SNAPSHOT}.tar.xz ${CARGO_SNAPSHOT}.tar.xz\n</code></pre></li> <li>Keep the terminal open for the next step</li> </ul> </li> <li>Update the checksums in <code>poky/meta/recipes-devtools/rust/rust-source.inc</code><ul> <li>Download the files:     <pre><code>wget \"https://static.rust-lang.org/dist/rustc-${RS_VERSION}-src.tar.xz\"\n</code></pre></li> <li>Generate the checksums in the same terminal:     <pre><code>sha256sum \"rustc-${RS_VERSION}-src.tar.xz\"\n</code></pre></li> </ul> </li> <li>Run <code>bitbake nao-image</code> within the build shell<ul> <li>Errors similar to <code>libstd-rs-1.63.0-r0 do_patch: Applying patch...</code> often mean that patches are obsolete.     These patches are located in <code>poky/meta/recipes-devtools/rust/libstd-rs/</code> and <code>poky/meta/recipes-devtools/rust/rust-llvm/</code>.     Deleted patches need to be removed from their corresponding recipes.     Afterwards rerun the image build.</li> </ul> </li> <li>Once a successful build completed, create a patch from the changes in poky:<ul> <li><code>sh     cd poky/     git add .     git commit # ...     git format-patch HEAD~  # this generates 0001-....patch</code></li> <li>Copy the patch file into <code>meta-hulks/patches/0001....patch</code> and fix the patch path in <code>meta-hulks/kas-project.yml</code></li> </ul> </li> </ul>"},{"location":"setup/nao_setup/","title":"NAO Setup","text":"<p>This section assumes you have a working SDK installed. See Nao Image and SDK to learn how to acquire or build one.</p>"},{"location":"setup/nao_setup/#configuring-team-specific-data","title":"Configuring Team Specific Data","text":"HULKs MembersNon HULKs Members <p>There is nothing to do, all the configuration should be ready to if you cloned the <code>hulks/nao</code> repository.</p>"},{"location":"setup/nao_setup/#ssh-keys","title":"SSH Keys","text":"<p>If you built your own SDK, you should have created an SSH key pair. The public key is used during image creation and registered as an authorized key in the openssh configuration. All of our tools expect the private key to be located at <code>scripts/ssh_key</code>. If you did not create the SDK yourself, ask your teammates for the key.</p>"},{"location":"setup/nao_setup/#set-up-team-number","title":"Set up Team Number","text":"<p>In the HULKs code release, the SPL team number is hardcoded in a few places. Change this to your own team number before continuing.</p> <ul> <li><code>crates/spl_network/src/lib.rs</code> contains a constant called HULKS_TEAM_NUMBER. You may also wish to rename this constant.</li> <li><code>tools/pepsi</code> contains a bunch of <code>24</code>s, however most of them are in comments or CLI command help text.<ul> <li><code>tools/pepsi/src/parsers.rs</code> has a default and a check value that use 24 literals.</li> </ul> </li> <li><code>tools/twix/src/completion_edit.rs</code> generates IP address suggestions with a hardcoded team number.</li> <li><code>etc/parameters/hardware.json</code> has an attribute called spl for team communication hardcoded to 10024 (10000 + team number).</li> </ul>"},{"location":"setup/nao_setup/#set-up-hardware-ids","title":"Set up Hardware IDs","text":"<p>The tooling around our framework expects each NAO robot to have a number associated with it's hardware IDs. This number also determines the last octet of a robot's IP addresses. For example robot number <code>21</code> will always have the IPv4 addresses <code>10.0.X.21</code> (wireless) and <code>10.1.X.21</code> (ethernet) where X is the team number.</p> <p>For each robot you must determine it's head and body IDs and enter them in <code>etc/parameters/hardware_ids.json</code>. This file is used by pepsi and other tools to find the hardware ids belonging to a robot number.</p>"},{"location":"setup/nao_setup/#flashing-the-firmware","title":"Flashing the Firmware","text":"<p>You can flash the firmware both using pepsi or manually using an USB stick.</p> <p>Flashing with pepsi is done using the <code>gammaray</code> subcommand and is the preferred option. The following steps are only necessary for manual flashing with an USB stick.</p>"},{"location":"setup/nao_setup/#preparing-a-flash-stick","title":"Preparing a Flash-Stick","text":"<p>First, the firmware image has to be flashed to a USB stick. Use <code>lsblk</code> to make sure you are overwriting the correct device. <pre><code>lsblk\n</code></pre></p> <p>All existing data on the target device will be wiped! Replace <code>sdX</code> with the USB device. <pre><code>dd if=path-to-nao-image.opn of=/dev/sdX status=progress\n</code></pre></p> <p>Finally, run <code>sync</code> to make sure all data has actually been written to the stick before unplugging it. <pre><code>sync\n</code></pre></p>"},{"location":"setup/nao_setup/#flashing-the-nao","title":"Flashing the NAO","text":"<ul> <li>Make sure the robot is turned off and a charger is plugged in to prevent a sudden loss of power during the process.</li> <li>Plug the prepared USB stick into the back of the NAO's head.</li> <li>Hold the chest button for about 5 seconds until it starts glowing, then release immediately.   The chest button LED should now be flashing rapidly.</li> <li>Wait for the flashing process to finish</li> <li>The new firmare should be installed now.</li> </ul>"},{"location":"setup/nao_setup/#compiling-for-nao","title":"Compiling for NAO","text":"<p><code>./pepsi build --target nao</code> will compile the code for use on the NAO with the <code>incremental</code> cargo profile.</p>"},{"location":"setup/nao_setup/#uploading-to-the-nao","title":"Uploading to the NAO","text":"<p><code>./pepsi upload &lt;number&gt;</code> will first compile the code with the same <code>incremental</code> cargo profile and the upload the binary and configuration files to the robot with the specified number.</p>"},{"location":"setup/nao_setup/#remote-shell-access","title":"Remote Shell Access","text":"<p><code>./pepsi shell &lt;number&gt;</code> establishes an SSH connection and presents an interactive shell to the user.</p>"},{"location":"setup/overview/","title":"Overview","text":"<p>TODO: Symbolbild HULK mit pepsi</p> <p>This section describes the necessary steps to download the code, compile for the Webots simulator, how to prepare the NAO SDK and image using Yocto and finally how to compile and upload the software to a real NAO robot.</p>"},{"location":"tooling/aliveness/","title":"Aliveness","text":"<p>Aliveness is a system for querying status information from NAOs in the network. It consists of two parts: The service running on the NAOs and a client for sending aliveness requests to the network and processing answers.</p>"},{"location":"tooling/aliveness/#information-available-via-aliveness","title":"Information available via aliveness","text":"<p>The following information can be queried from NAOs connected via Ethernet:</p> <ul> <li>Hostname</li> <li>Current HULKs-OS version</li> <li>States of the systemd services for HAL, HuLA, HULK and LoLA</li> <li>Battery charge state and current</li> <li>Head ID</li> <li>Body ID</li> <li>Wireless network name</li> <li>Joint temperatures</li> <li>Name of the interface the beacon is received from (currently always enp4s0)</li> </ul>"},{"location":"tooling/aliveness/#aliveness-service","title":"Aliveness service","text":"<p>The aliveness service is built together with the HULKs-OS image and included in it. It is started upon the first connection with the network via Ethernet and listens for all messages send to the multicast address <code>224.0.0.42</code> as well as its own IP address.</p> <p>When receiving a UDP packet with content <code>BEACON</code>, it responds by sending the above described information encoded via JSON to the sender.</p>"},{"location":"tooling/aliveness/#aliveness-client","title":"Aliveness client","text":"<p>Pepsi includes a fully featured aliveness client with different verbosity levels and export options, see here for further information.</p> <p>Example usage:</p> <pre><code>./pepsi aliveness\n./pepsi aliveness 27 32\n./pepsi aliveness --json\n./pepsi aliveness --timeout 500 -v\n</code></pre> <p>When executing any of the aliveness subcommands in pepsi, it will send the aforementioned beacon message to the multicast address or to a list of NAO IP addresses. It then collects all responses within a timeout and filters their content according to the chosen verbosity level.</p>"},{"location":"tooling/aliveness/#potential-firewall-issues","title":"Potential firewall issues","text":"<p>When no NAO addresses are specified, the beacon is sent via multicast and the answers are received via unicast. Since the answers are from a different IP addresses, most firewalls may block them.</p> <p>In this case, the user has change their firewall settings to allow the incoming messages, e.g. for ufw by adding the following rule:</p> <pre><code>ufw allow proto udp from 10.1.24.0/24\n</code></pre>"},{"location":"tooling/overview/","title":"Overview","text":"<p>Apart from the NAO code our repository contains several tools to aid in the development and testing process:</p> <ul> <li>Pepsi: A multi-tool to automate repetitive tasks like compiling and deployment</li> <li>Twix: Our debugging tool to visualize live data from the NAO or a Webots simulation</li> <li>Depp: TODO: Irgendwas mit dependencies</li> <li>Fanta: TODO: Irgendwas mit live data auf der CLI</li> <li>Machine Learning: Our tooling to create datasets and neural networks</li> <li>Behavior Simulator: The simulator and viewer to debug and automatically test behavior</li> <li>Debugging with GDB/LLDB: How to use a debugger with our software</li> </ul>"},{"location":"tooling/pepsi/","title":"Pepsi","text":"<p>Pepsi is a multi-tool we use for anything related to the code or the NAO robots. It can be used to build the code, set up configuration parameters for a game, deploy to a robot or simply open a remote shell.</p> <p>This page is only meant as a general overview of pepsi's subcommands. For detailed usage instructions, run <code>pepsi --help</code> or <code>pepsi &lt;subcommand&gt; --help</code>.</p>"},{"location":"tooling/pepsi/#typical-webots-workflow","title":"Typical Webots Workflow","text":"<p>This is pretty simple. Open Webots, load the <code>webots/worlds/penalized_extern.wbt</code> world file and execute</p> <pre><code>./pepsi run\n</code></pre> <p>in your terminal. This will build (if necessary) and then run the webots binary. The simulation is paused automatically until the binary starts.</p>"},{"location":"tooling/pepsi/#typical-nao-workflow","title":"Typical NAO Workflow","text":"<pre><code>./pepsi upload &lt;number or IP&gt;\n</code></pre> <p>This command does the following:</p> <ul> <li>checks if a toolchain is installed, downloads, and installs one if necessary</li> <li>builds the code for the NAO target</li> <li>uploads binary, configuration parameters, motion files, neural networks, etc. to the NAO(s)</li> <li>restarts HULK service on the NAO(s)</li> </ul>"},{"location":"tooling/pepsi/#interaction-with-the-nao","title":"Interaction with the NAO","text":"<p>NAOs are identified either by IP or by number. Numbers are converted to IPs as follows:</p> <ul> <li><code>{number}</code> -&gt; <code>10.1.24.{number}</code></li> <li><code>{number}w</code> -&gt; <code>10.0.24.{number}</code></li> </ul> <p>Many subcommands can act on multiple robots concurrently.</p> <p><code>upload</code> builds a binary for the NAO target, and then uploads it and parameter files to one or more robot.</p> <p><code>wireless</code>, <code>reboot</code>, <code>poweroff</code>, and <code>hulk</code> directly interact with the robot(s), whereas <code>communication</code>, and <code>playernumber</code> only change the local configuration parameters.</p> <p><code>pregame</code> combines deactivating communication (to avoid sending illegal messages), assigning playernumbers, setting a wifi network, uploading, and restarting the HULK service.</p> <p><code>logs</code> or and <code>postgame</code> can be used after a (test-)game to download logs, the latter also shuts down the HULKs binary and disables wifi.</p> <p><code>gammaray</code> is used for flashing a HULKs-OS image to one or more robots.</p>"},{"location":"tooling/pepsi/#build-options","title":"Build Options","text":"<p>For subcommands that build a binary, you can specify a target and a build profile. These include <code>build</code>, <code>run</code>, <code>check</code>, and <code>clippy</code>. However <code>upload</code> and <code>pregame</code> only supports a profiles, since it doesn't make sense to upload a webots binary to the nao.</p>"},{"location":"tooling/pepsi/#aliveness","title":"Aliveness","text":"<p>Using the <code>aliveness</code> subcommand, pepsi can query information from NAOs connected via ethernet. By default, only irregular information like non-active services, outdated HULKs-OS versions and battery charge levels below 95% are displayed. Using <code>-v</code>/<code>--verbose</code> or <code>-j</code>/<code>--json</code>, you can retrieve all information available via aliveness in either a human- or machine-readable format.</p> <p>You can also set a timeout via <code>-t</code>/<code>--timeout</code> (defaulting to 200ms) and specify NAO addresses (e.g. <code>22</code> or <code>10.1.24.22</code>) for querying the aliveness information only from specific NAOs.</p> <p>Further information on the information available via aliveness as well as the details to the protocol can be found here.</p>"},{"location":"tooling/pepsi/#shell-completion","title":"Shell Completion","text":"<p>Shell completions can be generated using the <code>completions</code> subcommand.</p> <p>Example:</p> <pre><code>./pepsi completions zsh &gt; _pepsi\n</code></pre> <p>Refer to your shell's completion documentation for details.</p> <p>The shells completions for fish, zsh and bash include dynamic suggestions for all pepsi subcommands taking a NAO address as an argument (e.g. <code>pepsi upload</code>). Those suggestions are retrieved using the aliveness service and require a version of pepsi to be installed in the <code>PATH</code>, e.g. by using</p> <pre><code>cargo install --path tools/pepsi\n</code></pre> <p>and adding <code>~/.cargo/bin</code> to the <code>PATH</code>.</p>"},{"location":"workflow/competition/","title":"Competition","text":"<p>TODO</p>"},{"location":"workflow/competition/#meetings","title":"Meetings","text":"<p>TODO</p>"},{"location":"workflow/competition/#roles","title":"Roles","text":"<p>TODO</p>"},{"location":"workflow/development/","title":"Development","text":"<p>TODO</p>"},{"location":"workflow/development/#github","title":"GitHub","text":"<p>TODO</p>"},{"location":"workflow/development/#ci","title":"CI","text":"<p>TODO</p>"},{"location":"workflow/development/#the-development-project","title":"The Development Project","text":"<p>At HULKs we use a quite heavily modified version of the KanBan workflow. The Current Boards purpose is to visualize our current development status. The modifications were mainly done to address the fact that we do not have fixed working hours. Limiting the amount of cards that are in progress does not work. Especially for members that are not present on a daily basis. The List is mainly for organizing multiple iterations for a more long-term overview (important for dev-leads).</p>"},{"location":"workflow/development/#terms","title":"Terms","text":"<p>Assignee: The person that is responsible for a card (has the exclusive right to move a card(!) as soon as there is one). The assignee's job depends on the Kanban column:</p> <ul> <li>No assignee: Open, Done</li> <li>Assignee works on issue/pull request (if more or less progress happens on it): In Progress</li> <li>Assignee is responsible to bring a pull request to <code>main</code> (e.g. reviewer, tester): Request for Review</li> </ul> <p>Note that github distinguishes between reviewers and assignees. We also do that. Kind of. While the assignee (in most cases one person) is responsible for the card and bring the branch into the main, the reviewer(s) (can be more than one) can review the code at any time in addition to the notes that were given by the assignee. In general: The more reviewers the better the resulting code (That being said: feel free to review code).</p> Open In Progress Request for Review Done -------- Developer Reviewer -------- <p>Author: The person that created this card (issue/pull request). Responsible for answering questions (issues/pull requests) and implement/discuss requested changes (pull requests).</p>"},{"location":"workflow/development/#open","title":"Open","text":"<p>The Open section contains by the dev-leads selected issues that are important and of high priority for the current iteration. However, if you want to work on issues that are not in Open: Feel free to do so.</p> <p>Move (or add) an issue into In Progress and assign yourself when you started working on it.</p>"},{"location":"workflow/development/#in-progress","title":"In Progress","text":"<p>The In Progress section contains:</p> <ul> <li>issues that have an assignee, but no open pull request. As soon as there is an open pull request fixing this issue, the issue card should be replaced by this pull request card (removing the Issue from the Project but not closing it as it is not fixed in the main yet). The issue must then be mentioned with the <code>fixes #Issue_NO</code> in the pull requests description.</li> <li>pull requests that are not ready for review yet and are currently wip.</li> </ul> <p>Note: <code>fixes #Issue_NO</code> is a keyword on github. Github will automatically close the mentioned issue whenever the corresponding pull request was merged. Do not close issues that have not being fixed in the main yet (even if there is a pull request for it)!</p> <p>Move a pull request into Request for Review when you have finished your work and tested the pull request yourself on relevant platforms. At this stage a pull requests' description should be finalized (fill out the template properly).</p>"},{"location":"workflow/development/#request-for-review","title":"Request for Review","text":"<p>The Request for Review section contains pull requests that are ready to be reviewed. They don't need to be finished\u2122 for that, they can still be a draft pull request.</p> <p>Note: This section is a prioritized FIFO queue. Add new cards at the bottom. The head of development might decide to move it further up if the pull request is rather important.</p> <p>Note: Enable auto-merge if your pull request is not a draft pull request</p> <p>Assign yourself if you want to review this pull request.</p> <p>Conversation-Resolve-Policy: The person (the reviewer) who opened a conversation is the only one allowed to resolve it. The reviewer and author may use this policy to see which feedback has not been addressed yet.</p>"},{"location":"workflow/development/#meetings","title":"Meetings","text":"<p>We have a recurring Dev-Meeting every Wednesday, where we discuss all matters related to our development progress.</p>"},{"location":"workflow/development/#test-games","title":"Test Games","text":"<p>We regulary test our codebase in test games, usually after our Dev-Meeting</p>"},{"location":"workflow/development/#test-driven-development","title":"Test-driven development","text":"<p>TODO</p>"},{"location":"workflow/development/#unit-testing","title":"Unit testing","text":"<p>TODO</p>"},{"location":"workflow/development/#webots","title":"Webots","text":"<p>TODO</p>"},{"location":"workflow/development/#behavior-simulator","title":"Behavior Simulator","text":"<p>TODO</p>"},{"location":"workflow/engineering/","title":"Engineering","text":"<p>Team HULKs wants to sustain high quality and correct software for playing soccer at RoboCup. This requires common software engineering skills that are briefly covered on this page. Each feature that lands in the software in the end has a purpose and should fulfill the purpose well. The purpose is described with requirements which allow to design a solution that meets the requirements. The solution can later be implemented, tested, and integrated into the software.</p> <p>The section \"Tasks in large scale projects\" gives a rough outline over the software engineering duties. Team HULKs is interpreting this in the following ways:</p> <ul> <li>Requirements:<ul> <li>What problem do you want to solve?</li> <li>Is that problem worth solving? Cost vs. benefit, measure to acquire facts</li> <li>What is required?</li> <li>What is not required?</li> </ul> </li> <li>Design:<ul> <li>What components need to be touched/created?</li> <li>What properties have the components?</li> <li>What properties need to be added/modified/removed?</li> <li>How do the components interact?</li> <li>What data structures and algorithms should be used?</li> <li>What is the implementation plan?</li> <li>How can this design be tested?</li> </ul> </li> <li>Construction:<ul> <li>Design is implemented</li> <li>Tests are written during development to ensure correctness</li> <li>Measure</li> </ul> </li> <li>Evaluation:<ul> <li>Are the requirements fulfilled?</li> </ul> </li> </ul> <p>Each phase ends with a review of the artifacts, by a non-author.</p>"},{"location":"workflow/github_webhooks/","title":"GitHub Webhooks","text":"<p>The HULKs use HULKs/GitHubNotificationsBot for GitHub notifications in their messengers. Since we open-sourced our main repository, we do not have permissions to register webhooks in forks of the repository. This page serves a guide on how to setup and enable GitHub notifications from your repository.</p>"},{"location":"workflow/github_webhooks/#register-new-webhook","title":"Register New Webhook","text":"<ol> <li>In your forked repository, go to Settings, Webhooks, Add webhook</li> <li>Payload URL is <code>https://github-notifications.hulks.dev/</code></li> <li>Content type is <code>application/json</code></li> <li>Ask one of our Dev-Leads for the secret</li> <li>Leave SSL verification on</li> <li>Select \"Let me select individual events\" and enable the following:<ul> <li>Issue comments</li> <li>Issues</li> <li>Pull request review comments</li> <li>Pull request reviews</li> <li>Pull requests</li> <li>Pushes</li> </ul> </li> <li>Activate it and add it</li> <li>Profit</li> </ol>"},{"location":"workflow/github_webhooks/#adminstration-of-the-bot","title":"Adminstration of the Bot","text":"<p>The bot is running on the HULKs Nextcloud VM (RZ) machine. The address can be found the IP Address Range wiki page of the HULKsnition repository. A VPN connection is required to connect via SSH. The Docker Compose directory is located at <code>/mnt/ext/docker-config/web/</code> and the service is named <code>github-notifications</code>.</p>"},{"location":"workflow/leadership/","title":"Leadership","text":"<p>The goal of the team HULKs is to compete with other teams in the RoboCup Standard Platform League (SPL). Being competitive on such events with mostly part-time participating students requires optimal team performance and a focused development workflow to achieve set goals. Two members of the HULKs manage and lead the team towards the goals. These members are called development leads. Beside participating in normal development activities, development leads act by representing multiple roles where each has responsibilities.</p>"},{"location":"workflow/leadership/#roles-and-responsibilities","title":"Roles and Responsibilities","text":"<p>The following roles exist at the HULKs which craft the development leads.</p>"},{"location":"workflow/leadership/#technology-lead","title":"Technology Lead","text":"<p>Is responsible for technical specifications, architecture and its enforcement, and other technical areas.</p> <p>It identifies and fixes technical problems, consults the team or experts to acquire relevant information and makes decisions. Knowledge and guidance is given via pairing, code reviews, or meetings.</p>"},{"location":"workflow/leadership/#people-lead","title":"People Lead","text":"<p>Is responsible for enabling the team members to efficiently work with each other.</p> <p>It knows about interests, current activities, good and bad feelings of the team members. The people lead establishes a constructive and open feedback culture in the team but may also forward feedback between team members and honor good performances publicly. It supports building fitting groups, carefully breaks up unfitting groups, and manages group sizes. It may moderate within groups and connects multiple related groups together.</p>"},{"location":"workflow/leadership/#team-lead","title":"Team Lead","text":"<p>Is responsible for enabling the team to work on the set goals.</p> <p>It defines the development workflows, provides instructions and documentation, and monitors the team performance to derive improvements of the former. The team lead compares the required skills with the available skills of the team members and proposes ways to upskill. It connects newbies with experts and organizes/supervises team events and hackathons. It mentors newbies and supervises onboarding to technical topics. It ensures the propagation of our values, spirit, and quality demands to all team members. It engages that team members help and take over club activities.</p>"},{"location":"workflow/leadership/#recruiting-lead","title":"Recruiting Lead","text":"<p>Is responsible that the team remains to exist in the future.</p> <p>It ensures that the team regularly and strategically recruits new members. It actively takes part in the recruiting efforts and motivates other existing members to join the activities. The recruiting lead acts as the first-level contact person for new recruits, communicates with them, and encourages them to join the HULKs club. It actively reminds (not only) recruits to come to sign the club registration form and join our club activities, i.e., join meetings, being present in the lab, participate in organization and development activities.</p>"},{"location":"workflow/leadership/#project-management","title":"Project Management","text":"<p>Is responsible that the team achieves the set goals.</p> <p>It defines and prioritizes the goals aligned with the RoboCup rules that the team tries to achieve. The project management communicates the goals and ensures that each team member works towards their achievement within defined deadlines. It provides tasks that are derived from the goals and makes these tasks, together with a time plan, available to the team. It ensures and supports that the team makes progress on the tasks and helps to break them down into sub-tasks. It monitors work on the tasks, reminds to focus on essentials, notices blocked tasks and supports to unblock them, e.g., by connecting with experts or scheduling discussions in the team.</p>"},{"location":"workflow/overview/","title":"Overview","text":"<p>TODO: Elaborate</p> <ul> <li>Development workflow<ul> <li>GitHub<ul> <li>CI</li> <li>Board</li> </ul> </li> <li>Meetings<ul> <li>Test games</li> </ul> </li> <li>Test-driven development<ul> <li>Unit testing</li> <li>Webots</li> <li>Behavior Simulator</li> </ul> </li> </ul> </li> <li>Competition workflow<ul> <li>Meetings</li> <li>Roles</li> </ul> </li> </ul>"}]}